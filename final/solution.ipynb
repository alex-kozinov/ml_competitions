{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В интернет-галерее пользователи могут просматривать тысячи картинок произвольного содержания. При этом они совершают различные действия, например кликают на картинку чтобы увеличить её в размере или отложить её в избранное. Имея такую информацию, часто можно предугадать дальнейшие действия пользователя, на чём и основано большинство современных систем рекомендаций.\n",
    "\n",
    "В этой задаче вам предлагается создать свою собственную систему рекомендаций.\n",
    "\n",
    "Имея идентификаторы картинок, с которыми пользователи взаимодействовали, вам нужно предсказать, на какие картинки пользователи вероятнее всего кликнут. При этом картинки, на которые пользователи совершали клики в прошлом, не будут участвовать в оценке, даже если на них будет повторно совершён клик в будущем. Для предсказания множество картинок включает в себя все идентификаторы, которые представлены в файлах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename, use_days=False):\n",
    "    data = pd.read_csv('data/' + filename)\n",
    "    if use_days:\n",
    "        data.day = pd.to_datetime(data.day)\n",
    "        data.day = data.day.max() - data.day\n",
    "        data.day = (data.day / np.timedelta64(1, 'D')).astype(int)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def describe_df(data, name):\n",
    "    print('------------{}------------'.format(name))\n",
    "    print(data.shape)\n",
    "    print(data.head())\n",
    "    if 'day' in data.keys():\n",
    "        print('last day is {}'.format(np.max(data['day'])))\n",
    "\n",
    "def apk(actual, predicted, k=100): \n",
    "    \"\"\" \n",
    "    Computes the average precision at k. \n",
    "    This function computes the average prescision at k between two lists of \n",
    "    items. \n",
    "    Parameters \n",
    "    ---------- \n",
    "    actual : list \n",
    "             A list of elements that are to be predicted (order doesn’t matter) \n",
    "    predicted : list \n",
    "                A list of predicted elements (order does matter) \n",
    "    k : int, optional \n",
    "        The maximum number of predicted elements \n",
    "    Returns \n",
    "    ------- \n",
    "    score : double \n",
    "            The average precision at k over the input lists \n",
    "    \"\"\" \n",
    "    if len(predicted)>k: \n",
    "        predicted = predicted[:k] \n",
    " \n",
    "    score = 0.0 \n",
    "    num_hits = 0.0 \n",
    " \n",
    "    for i,p in enumerate(predicted): \n",
    "        if p in actual and p not in predicted[:i]: \n",
    "            num_hits += 1.0 \n",
    "            score += num_hits / (i+1.0) \n",
    " \n",
    "    if not actual: \n",
    "        return 0.0 \n",
    " \n",
    "    return score / min(len(actual), k) \n",
    "\n",
    "def mapk(actual, predicted, k=100): \n",
    "    \"\"\" \n",
    "    Computes the mean average precision at k. \n",
    "    This function computes the mean average prescision at k between two lists \n",
    "    of lists of items. \n",
    "    Parameters \n",
    "    ---------- \n",
    "    actual : list \n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn’t matter in the lists) \n",
    "    predicted : list \n",
    "                A list of lists of predicted elements \n",
    "                (order matters in the lists) \n",
    "    k : int, optional \n",
    "        The maximum number of predicted elements \n",
    "    Returns \n",
    "    ------- \n",
    "    score : double \n",
    "            The mean average precision at k over the input lists \n",
    "    \"\"\" \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(pic_id):\n",
    "    res = []\n",
    "    for d in descriptions[descriptions.picture_id==pic_id].description:\n",
    "        res = res + [int(tag) for tag in d.split()]\n",
    "    return np.array(res)\n",
    "    \n",
    "\n",
    "def get_dstream(data_frames):\n",
    "    \"\"\"\n",
    "    Compute sequence of user_id, image_id, date in \n",
    "    numpy array\n",
    "    Parameters\n",
    "    ---------- \n",
    "    data_frames : list\n",
    "                  A list of dataframes with columns user_id and picture_id\n",
    "    \n",
    "    Returns \n",
    "    ------- \n",
    "    stream : numpy array (3, W)\n",
    "            W is the total number of rows in data_frames\n",
    "            stream[0] - user_id list\n",
    "            stream[1] - image_id list\n",
    "            stream[0] - date list\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.array([])\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "    \n",
    "    for df in data_frames:\n",
    "        users = np.array(df.user_id)\n",
    "        items = np.array(df.picture_id)\n",
    "        days = np.array(df.day)\n",
    "        \n",
    "        data = np.hstack((data, days))\n",
    "        X = np.hstack((X, users))\n",
    "        Y = np.hstack((Y, items))\n",
    "        \n",
    "    stream = np.vstack((X, Y, data))\n",
    "    return stream\n",
    "\n",
    "def change_stream(stream):\n",
    "    data = np.array([])\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "\n",
    "    for user_id, picture_id, day in tqdm(stream.T):\n",
    "        tags = get_tags(picture_id)\n",
    "        users = np.ones_like(tags) * user_id\n",
    "        days = np.ones_like(tags) * day\n",
    "        \n",
    "        data = np.hstack((data, days))\n",
    "        X = np.hstack((X, users))\n",
    "        Y = np.hstack((Y, tags))\n",
    "    \n",
    "    new_stream = np.vstack((X, Y, data))\n",
    "    return new_stream\n",
    "\n",
    "def create_st(data_frames, max_cost):\n",
    "    \"\"\"\n",
    "    Create sparse table with different weights\n",
    "    \"\"\"\n",
    "    \n",
    "    stream = get_dstream(data_frames)\n",
    "    print(stream[0].shape)\n",
    "    print(stream[1].shape)\n",
    "    print(stream[2].shape)\n",
    "    stream[2] =  max_cost - stream[2] / 51. * (max_cost - 1)\n",
    "    \n",
    "    return coo_matrix((stream[2], (stream[0].astype(int), stream[1].astype(int))))\n",
    "\n",
    "def create_st_desc(data_frames, max_cost):\n",
    "    stream = change_stream(get_dstream(data_frames))\n",
    "    stream[2] =  max_cost - stream[2] / 51. * (max_cost - 1)\n",
    "    \n",
    "    return coo_matrix((stream[2], (stream[0], stream[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = load_df('train_clicks.csv', True)\n",
    "likes = load_df('train_likes.csv', True)\n",
    "shares = load_df('train_shares.csv', True)\n",
    "descriptions = load_df('descriptions.csv')\n",
    "themes = load_df('themes.csv')\n",
    "user_proﬁles = load_df('user_information.csv')\n",
    "test_users = ('test_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Выводим информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------clicks------------\n",
      "(2360862, 3)\n",
      "   user_id  picture_id  day\n",
      "0     1442      546149   43\n",
      "1     1442      546149   43\n",
      "2     1442     1242875   36\n",
      "3     1442     1242875   36\n",
      "4     1442     1242891   36\n",
      "last day is 51\n",
      "------------likes------------\n",
      "(308422, 3)\n",
      "   user_id  picture_id  day\n",
      "0   490982      298754    3\n",
      "1   490989     1060978   35\n",
      "2   490989      976274   35\n",
      "3   490989      976273   35\n",
      "4   490989      976272   35\n",
      "last day is 51\n",
      "------------shares------------\n",
      "(47867, 3)\n",
      "   user_id  picture_id  day\n",
      "0    24986      216354   37\n",
      "1    25046      514369   16\n",
      "2    25058     1066857   47\n",
      "3    25058      481307   47\n",
      "4    25058      636884   47\n",
      "last day is 51\n",
      "------------descriptions------------\n",
      "(1379875, 2)\n",
      "   picture_id                                        description\n",
      "0     1171496      734475 487260 884706 5941 48255 147285 969800\n",
      "1     1171497  488295 261184 466630 235887 642445 465419 9297...\n",
      "2     1171498                              724435 1003828 164020\n",
      "3     1171499  274351 96637 259690 590856 761704 148158 16580...\n",
      "4     1171500                 235887 117104 952749 285126 288206\n",
      "------------themes------------\n",
      "(914617, 2)\n",
      "   picture_id themes\n",
      "0           4     19\n",
      "1           5     19\n",
      "2           6     19\n",
      "3           7     19\n",
      "4           8     19\n",
      "------------user_proﬁles------------\n",
      "(4231420, 3)\n",
      "   user_id         day                                          embedding\n",
      "0   310618  2019-03-08  0.922 0.078 7.9e-05 0.062491 0.864 0.069111 0....\n",
      "1   310618  2019-03-09  0.922 0.078 7.9e-05 0.062491 0.864 0.069111 0....\n",
      "2   310618  2019-03-09  0.922 0.078 0.000159 0.034911 0.864 0.093347 0...\n",
      "3   310618  2019-03-10  0.922 0.078 0.000159 0.034911 0.864 0.093347 0...\n",
      "4   310618  2019-03-11  0.922 0.078 0.000171 0.04258 0.864 0.086733 0....\n",
      "last day is 2019-03-24\n"
     ]
    }
   ],
   "source": [
    "describe_df(clicks, 'clicks')\n",
    "describe_df(likes, 'likes')\n",
    "describe_df(shares, 'shares')\n",
    "describe_df(descriptions, 'descriptions')\n",
    "describe_df(themes, 'themes')\n",
    "describe_df(user_proﬁles, 'user_proﬁles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, table_csr):\n",
    "    rows = []\n",
    "    for user_id in test_users.user_id.values:\n",
    "        rows.append(model.recommend(user_id, table_csr, N=100))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def concat_predictions(pred_list, weights):\n",
    "    res = {}\n",
    "    for i, pred in enumerate(pred_list):\n",
    "        for img, val in pred:\n",
    "            if img not in res.keys():\n",
    "                res[img] = weights[i] * val\n",
    "            else:\n",
    "                res[img] += weights[i] * val\n",
    "            \n",
    "    return [i[0] for i in sorted(res.items(), key=lambda x: -x[1])[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "descriptions = descriptions.description.apply(pd.Series) \\\n",
    "    .merge(descriptions, right_index = True, left_index = True) \\\n",
    "    .drop([\"description\"], axis = 1) \\\n",
    "    .melt(id_vars = ['picture_id',], value_name = \"tag\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём разреженную матрицу пользователь — объект для трёх таблиц с разными весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2717151,)\n",
      "(2717151,)\n",
      "(2717151,)\n"
     ]
    }
   ],
   "source": [
    "user_item = create_st([clicks, likes, shares], 8)\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели будем использовать разложение матрицы с помощью метода ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение крокодила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=512, regularization=.2, iterations=600, num_threads=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600.0/600 [4:31:36<00:00, 27.75s/it]  \n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item.T.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(get_predictions(model, user_item_csr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение помощника 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_model1 = implicit.als.AlternatingLeastSquares(factors=256, regularization=.1, iterations=400, num_threads=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400.0/400 [17:12<00:00,  2.61s/it]\n"
     ]
    }
   ],
   "source": [
    "help_model1.fit(user_item.T.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(get_predictions(help_model1, user_item_csr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение помощника 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_model2 = implicit.als.AlternatingLeastSquares(factors=512, regularization=.1, iterations=200, num_threads=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200.0/200 [37:58<00:00, 10.35s/it]\n"
     ]
    }
   ],
   "source": [
    "help_model2.fit(user_item.T.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(get_predictions(help_model2, user_item_csr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение помощника 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_model3 = implicit.als.AlternatingLeastSquares(factors=256, regularization=.2, iterations=500, num_threads=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500.0/500 [21:37<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "help_model3.fit(user_item.T.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(get_predictions(help_model3, user_item_csr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(predictions[0])):\n",
    "    usr_pred_list = [pred[i] for pred in predictions]\n",
    "    rows.append(concat_predictions(usr_pred_list, [1, 1, 0, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отформатируем идентификаторы как нужно для ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users['predictions'] = list(map(lambda x: ' '.join(map(str, x)), rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И запишем предсказания в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Новый подход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
